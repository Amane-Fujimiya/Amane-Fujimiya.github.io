---
layout: post
math: true
title: Future stuff - and preplanning
category: Devoted_Librarian
---

Recently, while working or commuting elsewhere on campus, I have been struck with either questions, or sentiments on quite the predicament on artificial intelligence. Or at least, what is supposed or assumed to be possible under such umbrella term in development. Well, what is even such thing that can be that worse? 

What do you remember of the most fundamental of the underlying machine learning and artificial intelligence development? Is it learning, is it some kind of structure, or architecture? Well, no. This fundamental assumption goes back to the 1950s, since the earlier day of the idea of artificial intelligence - the Dartmouth workshop of 1956. It is the **assumption** that artificial intelligence, by virtue of the abstract and arbitrary meaning of itself, that can be hosted and developed on the groundwork of computer system. Or rather, the philosophy of **computationalism**. 

What is inherently discussed of computationalism in this point and age, that is, you may ask? Well, quite a lot, actually. Computationalism under the eye of people is often interpreted as being rather, as computer being intelligent. Most people expected, or argued that this cannot be done, for the fact that there are also indeed people echoing the same opinion, for example, CRA of Searl, or the Godelian argument made by Brook, or Penrose. Overall, it is the conjecture that somehow got interpreted as computer being an artificial intelligent being got on people's nerve. 

To be fair, it is understandable why one might feel that way, in such uncertain stage of knowing if such assumption or goalpost is true or not, and even more so if they are wrong. Humans value themselves by their innate quality of being intelligent, or rational, of the more 'higher-order' morality that is exhibited, either from what they observed in life, or what they can indeed, rationalize upon. Said from such view, the fact that intelligence can be deduced from a somewhat soulless computational system, what is known in almost the entirety of its existence as being too normal, too tedious, too unimportant of its task - in certain part is true, since computer at its very core is just computation, but not a human calculator any more - suddenly becoming more human than one can accept, it is normal to expect such reaction from people. It would be a lie to say that I do not feel such thing in the same way or manner as of expected. 

However, without touching upon the morality of what can be considered "humanizing the computer", is computationalism actually false? Well, no. Even its usual interpretation is also wrong. The original (and more rational understanding) statement only states that computational system holds the **facility to simulate** intelligent construct, and perhaps nothing more than that. 

Computation and simulation itself can be thought of as a language, and in there, representations is the *non-binding*, *non-physical representation* of what is observed of the physical world - it is a simplified model in which the biggest factor resolved is the requirement of anything, for its bulky existence in physical form. And even then, who says that information flow, the little electrons in all the smallest semiconductor does not hold any physical interpretation? 

So, we do not know. Neither we want to believe it. Yet, perhaps we should think back on our assumption and let out a sigh of relief - because it is not telling you that your beloved computer is going sentient. Rather, it's something that the box named computer can provide existence of. Okay, well, tell that to the 2D lovers. They would be in joy. 